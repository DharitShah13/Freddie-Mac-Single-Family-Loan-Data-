{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import *\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import zipfile\n",
    "import datetime\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# H2O AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h2o\n",
    "from h2o.automl import H2OAutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321. connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>3 hours 53 mins</td></tr>\n",
       "<tr><td>H2O cluster timezone:</td>\n",
       "<td>America/New_York</td></tr>\n",
       "<tr><td>H2O data parsing timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.22.0.2</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>6 days </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_Abhinav_k0frpt</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>2.490 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>Algos, AutoML, Core V3, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.7.0 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  -------------------------------\n",
       "H2O cluster uptime:         3 hours 53 mins\n",
       "H2O cluster timezone:       America/New_York\n",
       "H2O data parsing timezone:  UTC\n",
       "H2O cluster version:        3.22.0.2\n",
       "H2O cluster version age:    6 days\n",
       "H2O cluster name:           H2O_from_python_Abhinav_k0frpt\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    2.490 Gb\n",
       "H2O cluster total cores:    4\n",
       "H2O cluster allowed cores:  4\n",
       "H2O cluster status:         locked, healthy\n",
       "H2O connection url:         http://localhost:54321\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         Algos, AutoML, Core V3, Core V4\n",
       "Python version:             3.7.0 final\n",
       "--------------------------  -------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "training_frame = h2o.import_file('historical_data1_Q12005.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_frame = training_frame.head(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows:10000\n",
      "Cols:27\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>       </th><th>fico              </th><th>dt_first_pi       </th><th>flag_fthb  </th><th>dt_matr           </th><th>cd_msa            </th><th>mi_pct            </th><th>cnt_units         </th><th>occpy_sts  </th><th>cltv              </th><th>dti               </th><th>orig_upb          </th><th>ltv              </th><th>int_rt            </th><th>channel  </th><th>ppmt_pnlty  </th><th>prod_type  </th><th>st  </th><th>prop_type  </th><th>zipcode          </th><th>id_loan     </th><th>loan_purpose  </th><th>orig_loan_term   </th><th>cnt_borr          </th><th>seller_name  </th><th>servicer_name      </th><th>flag_sc  </th><th>Year  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>type   </td><td>int               </td><td>int               </td><td>enum       </td><td>int               </td><td>int               </td><td>int               </td><td>int               </td><td>enum       </td><td>int               </td><td>int               </td><td>int               </td><td>int              </td><td>real              </td><td>enum     </td><td>enum        </td><td>enum       </td><td>enum</td><td>enum       </td><td>int              </td><td>string      </td><td>enum          </td><td>int              </td><td>int               </td><td>enum         </td><td>enum               </td><td>enum     </td><td>int   </td></tr>\n",
       "<tr><td>mins   </td><td>487.0             </td><td>200501.0          </td><td>           </td><td>203008.0          </td><td>0.0               </td><td>0.0               </td><td>1.0               </td><td>           </td><td>8.0               </td><td>2.0               </td><td>20000.0           </td><td>8.0              </td><td>4.875             </td><td>         </td><td>            </td><td>           </td><td>    </td><td>           </td><td>600.0            </td><td>NaN         </td><td>              </td><td>305.0            </td><td>1.0               </td><td>             </td><td>                   </td><td>         </td><td>2005.0</td></tr>\n",
       "<tr><td>mean   </td><td>726.4062999999998 </td><td>200503.08509999973</td><td>           </td><td>203500.90929999988</td><td>22347.025399999937</td><td>4.879100000000003 </td><td>1.0330000000000035</td><td>           </td><td>74.17049999999938 </td><td>49.85770000000005 </td><td>160097.30000000133</td><td>73.0383000000002 </td><td>5.809322199999983 </td><td>         </td><td>            </td><td>           </td><td>    </td><td>           </td><td>48512.24999999999</td><td>NaN         </td><td>              </td><td>359.8713999999997</td><td>1.6235000000000008</td><td>             </td><td>                   </td><td>         </td><td>2005.0</td></tr>\n",
       "<tr><td>maxs   </td><td>9999.0            </td><td>200912.0          </td><td>           </td><td>203504.0          </td><td>49740.0           </td><td>40.0              </td><td>4.0               </td><td>           </td><td>999.0             </td><td>999.0             </td><td>648000.0          </td><td>999.0            </td><td>8.25              </td><td>         </td><td>            </td><td>           </td><td>    </td><td>           </td><td>99900.0          </td><td>NaN         </td><td>              </td><td>360.0            </td><td>99.0              </td><td>             </td><td>                   </td><td>         </td><td>2005.0</td></tr>\n",
       "<tr><td>sigma  </td><td>214.49341846072187</td><td>4.110832991592619 </td><td>           </td><td>17.812630420297804</td><td>16603.632369579314</td><td>10.575285663124443</td><td>0.234342679956436 </td><td>           </td><td>18.525078882551586</td><td>112.84855307137543</td><td>80726.87604237828 </td><td>18.24974351665922</td><td>0.2509829241800769</td><td>         </td><td>            </td><td>           </td><td>    </td><td>           </td><td>26950.33671408201</td><td>NaN         </td><td>              </td><td>2.058466849035193</td><td>2.009365946051273 </td><td>             </td><td>                   </td><td>         </td><td>0.0   </td></tr>\n",
       "<tr><td>zeros  </td><td>0                 </td><td>0                 </td><td>           </td><td>0                 </td><td>2601              </td><td>8138              </td><td>0                 </td><td>           </td><td>0                 </td><td>0                 </td><td>0                 </td><td>0                </td><td>0                 </td><td>         </td><td>            </td><td>           </td><td>    </td><td>           </td><td>0                </td><td>0           </td><td>              </td><td>0                </td><td>0                 </td><td>             </td><td>                   </td><td>         </td><td>0     </td></tr>\n",
       "<tr><td>missing</td><td>0                 </td><td>0                 </td><td>0          </td><td>0                 </td><td>0                 </td><td>0                 </td><td>0                 </td><td>0          </td><td>0                 </td><td>0                 </td><td>0                 </td><td>0                </td><td>0                 </td><td>0        </td><td>0           </td><td>0          </td><td>0   </td><td>0          </td><td>0                </td><td>0           </td><td>0             </td><td>0                </td><td>0                 </td><td>0            </td><td>0                  </td><td>0        </td><td>0     </td></tr>\n",
       "<tr><td>0      </td><td>699.0             </td><td>200505.0          </td><td>N          </td><td>203504.0          </td><td>39300.0           </td><td>0.0               </td><td>1.0               </td><td>P          </td><td>56.0              </td><td>42.0              </td><td>190000.0          </td><td>56.0             </td><td>5.625             </td><td>R        </td><td>N           </td><td>FRM        </td><td>RI  </td><td>SF         </td><td>2800.0           </td><td>F105Q1000001</td><td>C             </td><td>360.0            </td><td>2.0               </td><td>Other sellers</td><td>USBANKNA           </td><td>N        </td><td>2005.0</td></tr>\n",
       "<tr><td>1      </td><td>691.0             </td><td>200504.0          </td><td>N          </td><td>203503.0          </td><td>36420.0           </td><td>25.0              </td><td>1.0               </td><td>P          </td><td>90.0              </td><td>36.0              </td><td>90000.0           </td><td>90.0             </td><td>5.75              </td><td>R        </td><td>N           </td><td>FRM        </td><td>OK  </td><td>SF         </td><td>73000.0          </td><td>F105Q1000002</td><td>N             </td><td>360.0            </td><td>1.0               </td><td>Other sellers</td><td>Other servicers    </td><td>N        </td><td>2005.0</td></tr>\n",
       "<tr><td>2      </td><td>713.0             </td><td>200503.0          </td><td>N          </td><td>203502.0          </td><td>28740.0           </td><td>0.0               </td><td>1.0               </td><td>P          </td><td>72.0              </td><td>45.0              </td><td>357000.0          </td><td>72.0             </td><td>6.0               </td><td>R        </td><td>N           </td><td>FRM        </td><td>NY  </td><td>SF         </td><td>12500.0          </td><td>F105Q1000003</td><td>P             </td><td>360.0            </td><td>2.0               </td><td>Other sellers</td><td>Other servicers    </td><td>N        </td><td>2005.0</td></tr>\n",
       "<tr><td>3      </td><td>719.0             </td><td>200505.0          </td><td>N          </td><td>203504.0          </td><td>0.0               </td><td>0.0               </td><td>1.0               </td><td>S          </td><td>85.0              </td><td>47.0              </td><td>195000.0          </td><td>68.0             </td><td>5.75              </td><td>R        </td><td>N           </td><td>FRM        </td><td>MO  </td><td>CO         </td><td>65000.0          </td><td>F105Q1000004</td><td>P             </td><td>360.0            </td><td>2.0               </td><td>Other sellers</td><td>USBANKNA           </td><td>N        </td><td>2005.0</td></tr>\n",
       "<tr><td>4      </td><td>656.0             </td><td>200503.0          </td><td>N          </td><td>203502.0          </td><td>40340.0           </td><td>0.0               </td><td>1.0               </td><td>P          </td><td>68.0              </td><td>30.0              </td><td>253000.0          </td><td>68.0             </td><td>5.625             </td><td>R        </td><td>N           </td><td>FRM        </td><td>MN  </td><td>SF         </td><td>55900.0          </td><td>F105Q1000005</td><td>C             </td><td>360.0            </td><td>2.0               </td><td>Other sellers</td><td>Other servicers    </td><td>N        </td><td>2005.0</td></tr>\n",
       "<tr><td>5      </td><td>641.0             </td><td>200504.0          </td><td>N          </td><td>203503.0          </td><td>19500.0           </td><td>30.0              </td><td>1.0               </td><td>P          </td><td>94.0              </td><td>41.0              </td><td>96000.0           </td><td>94.0             </td><td>6.25              </td><td>R        </td><td>N           </td><td>FRM        </td><td>IL  </td><td>SF         </td><td>62500.0          </td><td>F105Q1000006</td><td>N             </td><td>360.0            </td><td>1.0               </td><td>Other sellers</td><td>Other servicers    </td><td>N        </td><td>2005.0</td></tr>\n",
       "<tr><td>6      </td><td>646.0             </td><td>200505.0          </td><td>N          </td><td>203504.0          </td><td>17140.0           </td><td>0.0               </td><td>1.0               </td><td>P          </td><td>77.0              </td><td>43.0              </td><td>274000.0          </td><td>77.0             </td><td>6.125             </td><td>R        </td><td>N           </td><td>FRM        </td><td>KY  </td><td>SF         </td><td>41000.0          </td><td>F105Q1000007</td><td>N             </td><td>360.0            </td><td>2.0               </td><td>Other sellers</td><td>Other servicers    </td><td>N        </td><td>2005.0</td></tr>\n",
       "<tr><td>7      </td><td>586.0             </td><td>200503.0          </td><td>N          </td><td>203502.0          </td><td>28740.0           </td><td>0.0               </td><td>1.0               </td><td>P          </td><td>80.0              </td><td>34.0              </td><td>126000.0          </td><td>80.0             </td><td>6.125             </td><td>R        </td><td>N           </td><td>FRM        </td><td>NY  </td><td>PU         </td><td>12400.0          </td><td>F105Q1000008</td><td>P             </td><td>360.0            </td><td>2.0               </td><td>Other sellers</td><td>Other servicers    </td><td>N        </td><td>2005.0</td></tr>\n",
       "<tr><td>8      </td><td>582.0             </td><td>200503.0          </td><td>N          </td><td>203502.0          </td><td>0.0               </td><td>0.0               </td><td>1.0               </td><td>P          </td><td>80.0              </td><td>41.0              </td><td>88000.0           </td><td>80.0             </td><td>5.625             </td><td>R        </td><td>N           </td><td>FRM        </td><td>WA  </td><td>MH         </td><td>98900.0          </td><td>F105Q1000009</td><td>P             </td><td>360.0            </td><td>2.0               </td><td>Other sellers</td><td>Other servicers    </td><td>N        </td><td>2005.0</td></tr>\n",
       "<tr><td>9      </td><td>720.0             </td><td>200503.0          </td><td>N          </td><td>203502.0          </td><td>36500.0           </td><td>30.0              </td><td>1.0               </td><td>P          </td><td>95.0              </td><td>32.0              </td><td>200000.0          </td><td>95.0             </td><td>5.5               </td><td>T        </td><td>N           </td><td>FRM        </td><td>WA  </td><td>CO         </td><td>98500.0          </td><td>F105Q1000010</td><td>P             </td><td>360.0            </td><td>1.0               </td><td>Other sellers</td><td>PNCMTGESERVICES,INC</td><td>N        </td><td>2005.0</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_frame.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "testing_frame = h2o.import_file('historical_data1_Q22005.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_frame = testing_frame.head(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = training_frame.columns\n",
    "y = 'int_rt'\n",
    "X.remove(y)\n",
    "\n",
    "#Unnecessary Columns\n",
    "X.remove('Year')\n",
    "X.remove('servicer_name')\n",
    "X.remove('seller_name')\n",
    "X.remove('id_loan')\n",
    "X.remove('zipcode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "aml = H2OAutoML(max_runtime_secs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML progress: |████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "aml.train(x = X, y = y, training_frame = training_frame, leaderboard_frame= testing_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>mean_residual_deviance</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mse</th>\n",
       "      <th>mae</th>\n",
       "      <th>rmsle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DeepLearning_grid_1_AutoML_20181128_154512_mod...</td>\n",
       "      <td>0.098466</td>\n",
       "      <td>0.313793</td>\n",
       "      <td>0.098466</td>\n",
       "      <td>0.230591</td>\n",
       "      <td>0.044139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GBM_grid_1_AutoML_20181128_154512_model_2</td>\n",
       "      <td>0.105210</td>\n",
       "      <td>0.324362</td>\n",
       "      <td>0.105210</td>\n",
       "      <td>0.249206</td>\n",
       "      <td>0.045785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>StackedEnsemble_BestOfFamily_AutoML_20181128_1...</td>\n",
       "      <td>0.105809</td>\n",
       "      <td>0.325283</td>\n",
       "      <td>0.105809</td>\n",
       "      <td>0.251722</td>\n",
       "      <td>0.045968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GBM_grid_1_AutoML_20181128_154512_model_15</td>\n",
       "      <td>0.107560</td>\n",
       "      <td>0.327964</td>\n",
       "      <td>0.107560</td>\n",
       "      <td>0.251295</td>\n",
       "      <td>0.046274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GLM_grid_1_AutoML_20181128_154512_model_1</td>\n",
       "      <td>0.108196</td>\n",
       "      <td>0.328932</td>\n",
       "      <td>0.108196</td>\n",
       "      <td>0.249732</td>\n",
       "      <td>0.046420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GBM_grid_1_AutoML_20181128_154512_model_12</td>\n",
       "      <td>0.108485</td>\n",
       "      <td>0.329371</td>\n",
       "      <td>0.108485</td>\n",
       "      <td>0.250015</td>\n",
       "      <td>0.046416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GBM_grid_1_AutoML_20181128_154512_model_14</td>\n",
       "      <td>0.108493</td>\n",
       "      <td>0.329383</td>\n",
       "      <td>0.108493</td>\n",
       "      <td>0.255347</td>\n",
       "      <td>0.046558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GBM_grid_1_AutoML_20181128_154512_model_17</td>\n",
       "      <td>0.108790</td>\n",
       "      <td>0.329833</td>\n",
       "      <td>0.108790</td>\n",
       "      <td>0.256734</td>\n",
       "      <td>0.046699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GBM_grid_1_AutoML_20181128_154512_model_11</td>\n",
       "      <td>0.109393</td>\n",
       "      <td>0.330745</td>\n",
       "      <td>0.109393</td>\n",
       "      <td>0.257228</td>\n",
       "      <td>0.046781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GBM_5_AutoML_20181128_154512</td>\n",
       "      <td>0.109617</td>\n",
       "      <td>0.331085</td>\n",
       "      <td>0.109617</td>\n",
       "      <td>0.257421</td>\n",
       "      <td>0.046793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GBM_grid_1_AutoML_20181128_154512_model_18</td>\n",
       "      <td>0.109773</td>\n",
       "      <td>0.331320</td>\n",
       "      <td>0.109773</td>\n",
       "      <td>0.256596</td>\n",
       "      <td>0.046782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>StackedEnsemble_AllModels_AutoML_20181128_154512</td>\n",
       "      <td>0.110796</td>\n",
       "      <td>0.332861</td>\n",
       "      <td>0.110796</td>\n",
       "      <td>0.259862</td>\n",
       "      <td>0.047080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GBM_grid_1_AutoML_20181128_154512_model_8</td>\n",
       "      <td>0.111990</td>\n",
       "      <td>0.334650</td>\n",
       "      <td>0.111990</td>\n",
       "      <td>0.252904</td>\n",
       "      <td>0.047150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GBM_grid_1_AutoML_20181128_154512_model_13</td>\n",
       "      <td>0.112036</td>\n",
       "      <td>0.334717</td>\n",
       "      <td>0.112036</td>\n",
       "      <td>0.254415</td>\n",
       "      <td>0.047178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>XRT_1_AutoML_20181128_154512</td>\n",
       "      <td>0.112953</td>\n",
       "      <td>0.336085</td>\n",
       "      <td>0.112953</td>\n",
       "      <td>0.262546</td>\n",
       "      <td>0.047595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>GBM_grid_1_AutoML_20181128_154512_model_6</td>\n",
       "      <td>0.113273</td>\n",
       "      <td>0.336560</td>\n",
       "      <td>0.113273</td>\n",
       "      <td>0.263816</td>\n",
       "      <td>0.047678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>GBM_1_AutoML_20181128_154512</td>\n",
       "      <td>0.115005</td>\n",
       "      <td>0.339124</td>\n",
       "      <td>0.115005</td>\n",
       "      <td>0.266567</td>\n",
       "      <td>0.048058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>GBM_3_AutoML_20181128_154512</td>\n",
       "      <td>0.115017</td>\n",
       "      <td>0.339141</td>\n",
       "      <td>0.115017</td>\n",
       "      <td>0.266175</td>\n",
       "      <td>0.048058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>GBM_4_AutoML_20181128_154512</td>\n",
       "      <td>0.115646</td>\n",
       "      <td>0.340068</td>\n",
       "      <td>0.115646</td>\n",
       "      <td>0.266870</td>\n",
       "      <td>0.048194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>DRF_1_AutoML_20181128_154512</td>\n",
       "      <td>0.115822</td>\n",
       "      <td>0.340326</td>\n",
       "      <td>0.115822</td>\n",
       "      <td>0.265948</td>\n",
       "      <td>0.048229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>GBM_2_AutoML_20181128_154512</td>\n",
       "      <td>0.116577</td>\n",
       "      <td>0.341434</td>\n",
       "      <td>0.116577</td>\n",
       "      <td>0.267896</td>\n",
       "      <td>0.048370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>GBM_grid_1_AutoML_20181128_154512_model_9</td>\n",
       "      <td>0.120658</td>\n",
       "      <td>0.347359</td>\n",
       "      <td>0.120658</td>\n",
       "      <td>0.273516</td>\n",
       "      <td>0.049317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>GBM_grid_1_AutoML_20181128_154512_model_4</td>\n",
       "      <td>0.123405</td>\n",
       "      <td>0.351290</td>\n",
       "      <td>0.123405</td>\n",
       "      <td>0.264767</td>\n",
       "      <td>0.049545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>GBM_grid_1_AutoML_20181128_154512_model_3</td>\n",
       "      <td>0.123434</td>\n",
       "      <td>0.351332</td>\n",
       "      <td>0.123434</td>\n",
       "      <td>0.264772</td>\n",
       "      <td>0.049551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>GBM_grid_1_AutoML_20181128_154512_model_5</td>\n",
       "      <td>0.123479</td>\n",
       "      <td>0.351395</td>\n",
       "      <td>0.123479</td>\n",
       "      <td>0.264795</td>\n",
       "      <td>0.049560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>DeepLearning_1_AutoML_20181128_154512</td>\n",
       "      <td>0.126067</td>\n",
       "      <td>0.355059</td>\n",
       "      <td>0.126067</td>\n",
       "      <td>0.280533</td>\n",
       "      <td>0.050306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>DeepLearning_grid_1_AutoML_20181128_154512_mod...</td>\n",
       "      <td>0.130813</td>\n",
       "      <td>0.361681</td>\n",
       "      <td>0.130813</td>\n",
       "      <td>0.279744</td>\n",
       "      <td>0.052057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>GBM_grid_1_AutoML_20181128_154512_model_1</td>\n",
       "      <td>0.137413</td>\n",
       "      <td>0.370692</td>\n",
       "      <td>0.137413</td>\n",
       "      <td>0.289958</td>\n",
       "      <td>0.053155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>DeepLearning_grid_1_AutoML_20181128_154512_mod...</td>\n",
       "      <td>0.140104</td>\n",
       "      <td>0.374304</td>\n",
       "      <td>0.140104</td>\n",
       "      <td>0.294270</td>\n",
       "      <td>0.053030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>GBM_grid_1_AutoML_20181128_154512_model_16</td>\n",
       "      <td>0.144931</td>\n",
       "      <td>0.380698</td>\n",
       "      <td>0.144931</td>\n",
       "      <td>0.302623</td>\n",
       "      <td>0.054417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>GBM_grid_1_AutoML_20181128_154512_model_10</td>\n",
       "      <td>0.168156</td>\n",
       "      <td>0.410068</td>\n",
       "      <td>0.168156</td>\n",
       "      <td>0.325437</td>\n",
       "      <td>0.059179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>GBM_grid_1_AutoML_20181128_154512_model_7</td>\n",
       "      <td>0.352347</td>\n",
       "      <td>0.593588</td>\n",
       "      <td>0.352347</td>\n",
       "      <td>0.466132</td>\n",
       "      <td>0.086228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             model_id  mean_residual_deviance  \\\n",
       "0   DeepLearning_grid_1_AutoML_20181128_154512_mod...                0.098466   \n",
       "1           GBM_grid_1_AutoML_20181128_154512_model_2                0.105210   \n",
       "2   StackedEnsemble_BestOfFamily_AutoML_20181128_1...                0.105809   \n",
       "3          GBM_grid_1_AutoML_20181128_154512_model_15                0.107560   \n",
       "4           GLM_grid_1_AutoML_20181128_154512_model_1                0.108196   \n",
       "5          GBM_grid_1_AutoML_20181128_154512_model_12                0.108485   \n",
       "6          GBM_grid_1_AutoML_20181128_154512_model_14                0.108493   \n",
       "7          GBM_grid_1_AutoML_20181128_154512_model_17                0.108790   \n",
       "8          GBM_grid_1_AutoML_20181128_154512_model_11                0.109393   \n",
       "9                        GBM_5_AutoML_20181128_154512                0.109617   \n",
       "10         GBM_grid_1_AutoML_20181128_154512_model_18                0.109773   \n",
       "11   StackedEnsemble_AllModels_AutoML_20181128_154512                0.110796   \n",
       "12          GBM_grid_1_AutoML_20181128_154512_model_8                0.111990   \n",
       "13         GBM_grid_1_AutoML_20181128_154512_model_13                0.112036   \n",
       "14                       XRT_1_AutoML_20181128_154512                0.112953   \n",
       "15          GBM_grid_1_AutoML_20181128_154512_model_6                0.113273   \n",
       "16                       GBM_1_AutoML_20181128_154512                0.115005   \n",
       "17                       GBM_3_AutoML_20181128_154512                0.115017   \n",
       "18                       GBM_4_AutoML_20181128_154512                0.115646   \n",
       "19                       DRF_1_AutoML_20181128_154512                0.115822   \n",
       "20                       GBM_2_AutoML_20181128_154512                0.116577   \n",
       "21          GBM_grid_1_AutoML_20181128_154512_model_9                0.120658   \n",
       "22          GBM_grid_1_AutoML_20181128_154512_model_4                0.123405   \n",
       "23          GBM_grid_1_AutoML_20181128_154512_model_3                0.123434   \n",
       "24          GBM_grid_1_AutoML_20181128_154512_model_5                0.123479   \n",
       "25              DeepLearning_1_AutoML_20181128_154512                0.126067   \n",
       "26  DeepLearning_grid_1_AutoML_20181128_154512_mod...                0.130813   \n",
       "27          GBM_grid_1_AutoML_20181128_154512_model_1                0.137413   \n",
       "28  DeepLearning_grid_1_AutoML_20181128_154512_mod...                0.140104   \n",
       "29         GBM_grid_1_AutoML_20181128_154512_model_16                0.144931   \n",
       "30         GBM_grid_1_AutoML_20181128_154512_model_10                0.168156   \n",
       "31          GBM_grid_1_AutoML_20181128_154512_model_7                0.352347   \n",
       "\n",
       "        rmse       mse       mae     rmsle  \n",
       "0   0.313793  0.098466  0.230591  0.044139  \n",
       "1   0.324362  0.105210  0.249206  0.045785  \n",
       "2   0.325283  0.105809  0.251722  0.045968  \n",
       "3   0.327964  0.107560  0.251295  0.046274  \n",
       "4   0.328932  0.108196  0.249732  0.046420  \n",
       "5   0.329371  0.108485  0.250015  0.046416  \n",
       "6   0.329383  0.108493  0.255347  0.046558  \n",
       "7   0.329833  0.108790  0.256734  0.046699  \n",
       "8   0.330745  0.109393  0.257228  0.046781  \n",
       "9   0.331085  0.109617  0.257421  0.046793  \n",
       "10  0.331320  0.109773  0.256596  0.046782  \n",
       "11  0.332861  0.110796  0.259862  0.047080  \n",
       "12  0.334650  0.111990  0.252904  0.047150  \n",
       "13  0.334717  0.112036  0.254415  0.047178  \n",
       "14  0.336085  0.112953  0.262546  0.047595  \n",
       "15  0.336560  0.113273  0.263816  0.047678  \n",
       "16  0.339124  0.115005  0.266567  0.048058  \n",
       "17  0.339141  0.115017  0.266175  0.048058  \n",
       "18  0.340068  0.115646  0.266870  0.048194  \n",
       "19  0.340326  0.115822  0.265948  0.048229  \n",
       "20  0.341434  0.116577  0.267896  0.048370  \n",
       "21  0.347359  0.120658  0.273516  0.049317  \n",
       "22  0.351290  0.123405  0.264767  0.049545  \n",
       "23  0.351332  0.123434  0.264772  0.049551  \n",
       "24  0.351395  0.123479  0.264795  0.049560  \n",
       "25  0.355059  0.126067  0.280533  0.050306  \n",
       "26  0.361681  0.130813  0.279744  0.052057  \n",
       "27  0.370692  0.137413  0.289958  0.053155  \n",
       "28  0.374304  0.140104  0.294270  0.053030  \n",
       "29  0.380698  0.144931  0.302623  0.054417  \n",
       "30  0.410068  0.168156  0.325437  0.059179  \n",
       "31  0.593588  0.352347  0.466132  0.086228  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aml.leaderboard.as_data_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TPOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tpot import TPOTRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpot = TPOTRegressor(generations=2, population_size=50,\n",
    "                     offspring_size=None,\n",
    "                     mutation_rate=0.9,\n",
    "                     verbosity=3,cv=2,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('historical_data1_Q12005.csv',low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('historical_data1_Q22005.csv',low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkAllReqColumns(df):\n",
    "    cols_to_keep = ['fico','flag_fthbN','flag_fthbX','flag_fthbY','mi_pct','cnt_units','occpy_stsl','occpy_stsO','occpy_stsS','cltv','dti','orig_upb','ltv','int_rt','channelB','channelC','channelR','channelT','ppmt_pnltyN','ppmt_pnltyX','ppmt_pnltyY','prop_typeCO','prop_typeCP','prop_typeLH','prop_typeMH','prop_typePU','prop_typeSF','prop_typeXX','loan_purposeC','loan_purposeN','loan_purposeP','orig_loan_term','cnt_borr']\n",
    "    \n",
    "    for x in cols_to_keep:\n",
    "        if not x in df.columns:\n",
    "            df[x] = 0.0\n",
    "            \n",
    "    df = df._get_numeric_data()\n",
    "    df.drop('cd_msa',axis=1,inplace=True)\n",
    "    df.drop('dt_first_pi',axis=1,inplace=True)\n",
    "    df.drop('dt_matr',axis=1,inplace=True)\n",
    "    df.drop('flag_sc',axis=1,inplace=True)\n",
    "    df.drop('zipcode',axis=1,inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_for_model(df):\n",
    "    dummies1 = pd.get_dummies(df['flag_fthb']).rename(columns=lambda x: 'flag_fthb' + str(x))\n",
    "    train_df = pd.concat([df, dummies1], axis=1)\n",
    "    \n",
    "    dummies2 = pd.get_dummies(df['occpy_sts']).rename(columns=lambda x: 'occpy_sts' + str(x)) \n",
    "    train_df = pd.concat([train_df, dummies2], axis=1)\n",
    "    \n",
    "    dummies3 = pd.get_dummies(df['channel']).rename(columns=lambda x: 'channel' + str(x)) \n",
    "    train_df = pd.concat([train_df, dummies3], axis=1)\n",
    "    \n",
    "    dummies4 = pd.get_dummies(df['ppmt_pnlty']).rename(columns=lambda x: 'ppmt_pnlty' + str(x)) \n",
    "    train_df = pd.concat([train_df, dummies4], axis=1)\n",
    "    \n",
    "    dummies5 = pd.get_dummies(df['prop_type']).rename(columns=lambda x: 'prop_type' + str(x)) \n",
    "    train_df = pd.concat([train_df, dummies5], axis=1)\n",
    "    \n",
    "    dummies6 = pd.get_dummies(df['loan_purpose']).rename(columns=lambda x: 'loan_purpose' + str(x)) \n",
    "    train_df = pd.concat([train_df, dummies6], axis=1)\n",
    "    \n",
    "    train_df['flag_sc'] = train_df['flag_sc'].map({'Y':1,'N':0})\n",
    "    \n",
    "    train_df = checkAllReqColumns(train_df)\n",
    "    \n",
    "    return train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_train = prepare_data_for_model(df_train)\n",
    "processed_test = prepare_data_for_model(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = processed_train.drop('int_rt',axis=1)\n",
    "y_train = processed_train['int_rt']\n",
    "\n",
    "X_test = processed_test.drop('int_rt',axis=1)\n",
    "y_test = processed_test['int_rt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: xgboost.XGBRegressor is not available and will not be used by TPOT.\n",
      "28 operators have been imported by TPOT.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Optimization Progress', max=150), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped pipeline #8 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #15 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #21 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #23 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #26 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #36 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #46 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #50 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #52 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #57 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #59 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #61 due to time out. Continuing to the next pipeline.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 __init__() got an unexpected keyword argument 'max_depth'\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 __init__() got an unexpected keyword argument 'max_depth'\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 __init__() got an unexpected keyword argument 'max_depth'\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 __init__() got an unexpected keyword argument 'max_depth'\n",
      "Skipped pipeline #65 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #67 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #70 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #74 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #76 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #80 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #83 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #87 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #90 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #92 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #95 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #97 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #101 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #104 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #107 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #110 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #113 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #116 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #121 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #123 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #126 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #128 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #133 due to time out. Continuing to the next pipeline.\n",
      "Generation 1 - Current Pareto front scores:\n",
      "-1\t-0.1412886734149891\tDecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=8, DecisionTreeRegressor__min_samples_split=10)\n",
      "-2\t-0.13770372229036182\tDecisionTreeRegressor(PCA(input_matrix, PCA__iterated_power=7, PCA__svd_solver=randomized), DecisionTreeRegressor__max_depth=10, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=4)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Skipped pipeline #139 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #145 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #151 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #157 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #161 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #166 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #181 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #188 due to time out. Continuing to the next pipeline.\n",
      "Generation 2 - Current Pareto front scores:\n",
      "-1\t-0.1412886734149891\tDecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=8, DecisionTreeRegressor__min_samples_split=10)\n",
      "-2\t-0.09536537896236935\tLinearSVR(MinMaxScaler(input_matrix), LinearSVR__C=0.01, LinearSVR__dual=True, LinearSVR__epsilon=0.01, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=1e-05)\n",
      "\n",
      "\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TPOTRegressor(config_dict=None, crossover_rate=0.1, cv=2,\n",
       "       disable_update_check=False, early_stop=None, generations=2,\n",
       "       max_eval_time_mins=5, max_time_mins=None, memory=None,\n",
       "       mutation_rate=0.9, n_jobs=-1, offspring_size=None,\n",
       "       periodic_checkpoint_folder=None, population_size=50,\n",
       "       random_state=None, scoring=None, subsample=1.0, use_dask=False,\n",
       "       verbosity=3, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpot.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE of TPOT Regressor is -0.10542476070776394\n"
     ]
    }
   ],
   "source": [
    "print('The RMSE of TPOT Regressor is {}'.format(tpot.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpot.export('tpot_freddiemac_pipeline.py')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
